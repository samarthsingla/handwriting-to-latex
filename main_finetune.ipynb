{"cells":[{"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2023-11-13T16:50:28.772900Z","iopub.status.busy":"2023-11-13T16:50:28.772514Z","iopub.status.idle":"2023-11-13T16:50:43.604811Z","shell.execute_reply":"2023-11-13T16:50:43.603822Z","shell.execute_reply.started":"2023-11-13T16:50:28.772868Z"}},"source":["%pip install numpy==1.26.2"]},{"cell_type":"code","execution_count":47,"metadata":{"execution":{"iopub.execute_input":"2023-11-26T17:45:43.395205Z","iopub.status.busy":"2023-11-26T17:45:43.394830Z","iopub.status.idle":"2023-11-26T17:45:47.951475Z","shell.execute_reply":"2023-11-26T17:45:47.950546Z","shell.execute_reply.started":"2023-11-26T17:45:43.395170Z"},"trusted":true},"outputs":[{"data":{"text/plain":["<contextlib.ExitStack at 0x2fadf4490>"]},"execution_count":47,"metadata":{},"output_type":"execute_result"}],"source":["import os\n","import torch\n","import pandas as pd\n","from skimage import io, transform\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms, utils\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","# Ignore warnings\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","import logging\n","\n","debug = logging.getLogger(\"Debug\")\n","info  = print\n","plt.ion()   # interactive mode"]},{"cell_type":"code","execution_count":48,"metadata":{"execution":{"iopub.execute_input":"2023-11-26T17:45:47.953504Z","iopub.status.busy":"2023-11-26T17:45:47.953026Z","iopub.status.idle":"2023-11-26T17:45:48.000046Z","shell.execute_reply":"2023-11-26T17:45:47.999026Z","shell.execute_reply.started":"2023-11-26T17:45:47.953477Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Running MPS Mode: mps\n"]}],"source":["#check GPU\n","device = None\n","if torch.cuda.is_available():\n","    device = torch.device(\"cuda\")\n","    print(\"Running CUDA Mode:\", device, torch.cuda.get_device_name(0))\n","elif torch.backends.mps.is_available():\n","    device = torch.device(\"mps\")\n","    print(\"Running MPS Mode:\", device)\n","else:\n","    device = torch.device(\"cpu\")\n","    print(\"Running CPU Mode:\", device)\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["## Data and Classes\n","- Create Dataloader class\n","\n","Note: Working on Part (a) as of now.  \n","Guiding light: https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html"]},{"cell_type":"code","execution_count":49,"metadata":{"execution":{"iopub.execute_input":"2023-11-26T17:45:48.002138Z","iopub.status.busy":"2023-11-26T17:45:48.001614Z","iopub.status.idle":"2023-11-26T17:45:48.023218Z","shell.execute_reply":"2023-11-26T17:45:48.022126Z","shell.execute_reply.started":"2023-11-26T17:45:48.002103Z"},"trusted":true},"outputs":[],"source":["START_TOKEN = \"<START>\"\n","END_TOKEN = \"<END>\"\n","UNK_TOKEN = \"<UNK>\"\n","PAD_TOKEN = \"<PAD>\"\n","\n","class Vocabulary:\n","    def __init__(self, freq_dict, wd_to_id, id_to_wd):\n","        self.freq_dict = freq_dict\n","        self.wd_to_id = wd_to_id\n","        self.id_to_wd = id_to_wd\n","        self.N = len(freq_dict)\n","    \n","    def get_id(self, word):\n","        if word in self.wd_to_id:\n","            return self.wd_to_id[word]\n","        else:\n","            return self.wd_to_id[UNK_TOKEN]\n","        \n","    def decode(self, formula):\n","        \"\"\"\n","        Input shape: (seq_len,)\n","        Output Shape: seq_len -> python list\n","        \"\"\"\n","        # decoded = []\n","        # for id in formula:\n","        #     idx = id.item()\n","        #     if idx in self.id_to_wd:\n","        #         decoded.append(self.id_to_wd[idx])\n","        #     else:\n","        #         decoded.append(UNK_TOKEN)\n","        return \" \".join([self.id_to_wd[idx.item()] for idx in formula])\n","\n","class LatexFormulaDataset(Dataset):\n","    \"\"\"Latex Formula Dataset: Image and Text\"\"\"\n","    \n","    def __init__(self, csv_file, root_dir, transform = None, max_examples = None, vocab=None):\n","        \"\"\"\n","        Arguments:\n","            csv_file (string): Path to the csv file with image name and text\n","            root_dir (string): Directory with all the images.\n","            transform (callable, optional): Optional transform to be applied\n","                on a sample.\n","        \"\"\"\n","        info(\"Loading Dataset...\")\n","        self.df = pd.read_csv(csv_file)\n","        info(\"Loaded.\")\n","        #info(\"Loaded Dataset\", self.df.info)\n","        self.externVocab = vocab\n","        #Slice the dataset if max_examples is not None\n","        if max_examples is not None:\n","            self.df = self.df.iloc[:max_examples, :]\n","\n","        self.root_dir = root_dir\n","        self.transform = transform\n","\n","        self.df['formula'] = self.df['formula'].apply(lambda x: x.split())\n","        self.df['formula'] = self.df['formula'].apply(lambda x: [START_TOKEN] + x + [END_TOKEN])\n","\n","        self.maxlen = 0\n","        for formula in self.df['formula']:\n","            if len(formula) > self.maxlen:\n","                self.maxlen = len(formula)\n","        \n","        # def convert_to_ids(formula):\n","        #     form2 = [self.vocab.get_id(wd) for wd in formula]\n","        #     return torch.tensor(form2, dtype=torch.int64)\n","        \n","        self.df['formula'] = self.df['formula'].apply(lambda x: x +[PAD_TOKEN]*(self.maxlen - len(x)))\n","        self.vocab= self.construct_vocab() \n","        # self.df['formula'] = self.df['formula'].apply(convert_to_ids)\n","        \n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, idx):\n","        \"\"\"\n","        Returns sample of type image, textformula\n","        \"\"\"\n","        if torch.is_tensor(idx):\n","            idx = idx.tolist()\n","\n","        img_name = os.path.join(self.root_dir,\n","                                self.df.iloc[idx, 0])\n","        image = io.imread(img_name)\n","        formula = self.df.iloc[idx, 1]\n","\n","        # formula = np.array([formula], dtype=str).reshape(-1, 1)\n","        # formula = [self.vocab.get_id(wd[0]) for wd in formula]\n","        def convert_to_ids(formula):\n","            vocab = self.vocab\n","            if self.externVocab is not None:\n","                vocab = self.externVocab\n","            else:\n","                vocab = self.vocab\n","            form2 = [vocab.get_id(wd) for wd in formula]\n","            return torch.tensor(form2, dtype=torch.int64)\n","        \n","        formula = convert_to_ids(formula)\n","\n","        sample = {'image': image, 'formula': formula}\n","\n","        if self.transform:\n","            sample['image'] = self.transform(sample['image'])\n","            \n","        return sample \n","    \n","    def construct_vocab(self):\n","        \"\"\"\n","        Constructs vocabulary from the dataset formulas\n","        \"\"\"\n","        #Split on spaces to tokenize\n","        freq_dict = {}\n","        for formula in self.df['formula']:\n","            for wd in formula:\n","                if wd not in freq_dict:\n","                    freq_dict[wd] = 1\n","                else:\n","                    freq_dict[wd] += 1\n","        freq_dict[UNK_TOKEN] = 1\n","        N = len(freq_dict)\n","        wd_to_id = {}\n","        for i, wd in enumerate(freq_dict):\n","            wd_to_id[wd] = i\n","        #make id_to_wd a simple list\n","        id_to_wd = [None]*N\n","        for wd in wd_to_id:\n","            id_to_wd[wd_to_id[wd]] = wd\n","    \n","        #pad the formulas with \n","        return Vocabulary(freq_dict, wd_to_id, id_to_wd)      \n","\n","def get_dataloader(csv_path, image_root, batch_size, transform = None, max_examples = None, shuffle=True, externVocab=None):\n","    \"\"\"\n","    Returns dataloader,dataset for the dataset\n","    \"\"\"\n","    dataset = LatexFormulaDataset(csv_path, image_root, max_examples=max_examples,transform=transform, vocab=externVocab) #checked\n","    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n","    return dataloader, dataset\n"," "]},{"cell_type":"markdown","metadata":{},"source":["## Encoder Network\n","- A CNN to encode image to more meaningful vector"]},{"cell_type":"code","execution_count":50,"metadata":{"execution":{"iopub.execute_input":"2023-11-26T17:45:48.026284Z","iopub.status.busy":"2023-11-26T17:45:48.025441Z","iopub.status.idle":"2023-11-26T17:45:48.047135Z","shell.execute_reply":"2023-11-26T17:45:48.046335Z","shell.execute_reply.started":"2023-11-26T17:45:48.026256Z"},"trusted":true},"outputs":[],"source":["class EncoderCNN(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","    \n","        #@TODO:reduce number of layers: eliminate pools and acts\n","        self.conv1 = nn.Conv2d(3, 32, (5, 5))       \n","        self.conv2 = nn.Conv2d(32, 64, (5, 5))\n","        self.conv3 = nn.Conv2d(64, 128, (5, 5))        \n","        self.conv4 = nn.Conv2d(128, 256, (5, 5))        \n","        self.conv5 = nn.Conv2d(256, 512, (5, 5))\n","        \n","        self.pool = nn.MaxPool2d((2, 2))\n","        self.avg_pool = nn.AvgPool2d((3, 3))\n","    \n","    def forward(self, x):\n","        x = F.relu(self.conv1(x))\n","        x = self.pool(x)\n","        \n","        x = F.relu(self.conv2(x))\n","        x = self.pool(x)\n","        \n","        x = F.relu(self.conv3(x))\n","        x = self.pool(x)\n","        \n","        x = F.relu(self.conv4(x))\n","        x = self.pool(x)\n","        \n","        x = F.relu(self.conv5(x))\n","        x = self.pool(x)\n","        \n","        x = self.avg_pool(x)\n","        x = x.view(-1,512) \n","        # info(f\"Encoder Output Shape: {x.shape}\")\n","        return x\n","    \n","class DecoderLSTM(nn.Module):\n","    \"\"\"\n","    Inputs:\n","    (here M is whatever the batch size is passed)\n","\n","    context_size : size of the context vector [shape: (1,M,context_size)]\n","    n_layers: number of layers [for our purposes, defaults to 1]\n","    hidden_size : size of the hidden state vectors [shape: (n_layers,M,hidden_size)]\n","    embed_size : size of the embedding vectors [shape: (1,M,embed_size)]\n","    vocab_size : size of the vocabulary\n","    max_length : maximum length of the formula\n","    \"\"\"\n","    def __init__(self, context_size, vocab, max_seq_len, n_layers = 1, hidden_size = 512, embed_size = 512):\n","        super().__init__()\n","        self.context_size = context_size\n","        self.vocab = vocab\n","        self.vocab_size = vocab.N\n","        self.n_layers = n_layers\n","        self.hidden_size = hidden_size\n","        self.embed_size = embed_size\n","        self.input_size = context_size + embed_size\n","        self.max_seq_len = max_seq_len\n","\n","        self.embed = nn.Embedding(self.vocab_size, embed_size)\n","        self.lstm = nn.LSTMCell(self.input_size, self.hidden_size)\n","        self.linear = nn.Linear(hidden_size, self.vocab_size)\n","    \n","    def forward(self, context, target_tensor = None):\n","        \"\"\"\n","        M: batch_size\n","        context is the context vector from the encoder [shape: (M,context_size)]\n","        target_tensor is the formula in tensor form [shape: (M,max_length)] (in the second dimension, it is sequence of indices of formula tokens)\n","            if target_tensor is not None, then we are in Teacher Forcing mode\n","            else normal jo bhi (last prediction ka embed is concatenated)\n","        \"\"\"\n","        context.to(device)\n","        batch_size = context.shape[0]\n","\n","        #initialize hidden state and cell state\n","        hidden = context\n","        cell = torch.zeros(batch_size, self.hidden_size).to(device)\n","\n","        #initialize the input with embedding of the start token. Expand for batch size.\n","        init_embed = self.embed(torch.tensor([self.vocab.wd_to_id[START_TOKEN]]).to(device).expand(batch_size, -1)).squeeze()\n","        \n","        #initialize the output_history and init_output\n","        outputs = []\n","        output = torch.zeros((batch_size, self.vocab_size)).to(device)\n","        \n","        \n","        for i in range(self.max_seq_len):\n","            #teacher forcing: 50% times\n","            r = torch.rand(1)\n","            if r>0.5 and target_tensor is not None:\n","                if i==0 :\n","                    embedding = init_embed\n","                else: \n","                    embedding = self.embed(target_tensor[:, i-1]).reshape((batch_size, self.embed_size)).to(device)            \n","            else:\n","                if i==0 :\n","                    embedding = init_embed\n","                else:\n","                    #create embedding from previous input\n","                    embedding = self.embed(torch.argmax(output, dim = 1))\n","\n","            lstm_input = torch.cat([context, embedding], dim = 1).to(device)\n","    \n","            hidden, cell = self.lstm(lstm_input, (hidden, cell))\n","            output = self.linear(hidden)\n","            outputs.append(output)\n","            \n","        output_tensor = torch.stack(outputs).permute(1,0,2) #LBV - > BLV\n","\n","        return output_tensor, hidden, cell"]},{"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2023-11-13T18:15:56.106481Z","iopub.status.busy":"2023-11-13T18:15:56.105734Z","iopub.status.idle":"2023-11-13T18:15:56.198416Z","shell.execute_reply":"2023-11-13T18:15:56.197693Z","shell.execute_reply.started":"2023-11-13T18:15:56.106446Z"}},"source":["### Vocabulary\n","- https://github.com/harvardnlp/im2markup/blob/master"]},{"cell_type":"markdown","metadata":{},"source":["### Complete Network"]},{"cell_type":"code","execution_count":51,"metadata":{"execution":{"iopub.execute_input":"2023-11-26T17:45:48.048439Z","iopub.status.busy":"2023-11-26T17:45:48.048162Z","iopub.status.idle":"2023-11-26T17:45:48.062755Z","shell.execute_reply":"2023-11-26T17:45:48.061890Z","shell.execute_reply.started":"2023-11-26T17:45:48.048416Z"},"trusted":true},"outputs":[],"source":["class HandwritingToLatexModel(nn.Module):\n","    def __init__(self, context_size, vocab, max_seq_len, n_layers, hidden_size, embed_size):\n","        super().__init__()\n","        self.encoder = EncoderCNN()\n","        self.decoder = DecoderLSTM(context_size, vocab, max_seq_len, n_layers, hidden_size, embed_size)\n","    \n","    def forward(self, image, target_tensor = None):\n","        context = self.encoder(image)\n","        outputs, hidden, cell = self.decoder(context, target_tensor)\n","        return outputs"]},{"cell_type":"markdown","metadata":{},"source":["### Utility Functions"]},{"cell_type":"code","execution_count":52,"metadata":{"execution":{"iopub.execute_input":"2023-11-26T17:45:48.065258Z","iopub.status.busy":"2023-11-26T17:45:48.064884Z","iopub.status.idle":"2023-11-26T17:45:48.079212Z","shell.execute_reply":"2023-11-26T17:45:48.078198Z","shell.execute_reply.started":"2023-11-26T17:45:48.065224Z"},"trusted":true},"outputs":[],"source":["import time\n","import math\n","import matplotlib.pyplot as plt\n","import matplotlib.ticker as ticker\n","import numpy as np\n","from tqdm import tqdm\n","\n","plt.switch_backend('agg')\n","def asMinutes(s):\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return '%dm %ds' % (m, s)\n","def timeSince(since, percent):\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n","    \n","def saveModel(save_path, model_state, optimiser_state, loss):\n","    torch.save({\n","            'model_state_dict': model_state,\n","            'optimizer_state_dict':optimiser_state,\n","            'loss': loss,  \n","    }, save_path)"]},{"cell_type":"markdown","metadata":{},"source":["### Training Code.\n","- Dataloader automatically loads in batches. The data need not be modified by us."]},{"cell_type":"code","execution_count":53,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Loading Dataset...\n","Loaded.\n"]}],"source":["#part a\n","train_csv_path = \"data/SyntheticData/train.csv\"\n","image_root_path = \"data/SyntheticData/images/\"\n","train_dataloader, train_dataset = get_dataloader(train_csv_path, image_root_path, 32, transform, max_examples=None)"]},{"cell_type":"code","execution_count":54,"metadata":{"execution":{"iopub.execute_input":"2023-11-26T17:45:48.081574Z","iopub.status.busy":"2023-11-26T17:45:48.080335Z","iopub.status.idle":"2023-11-26T17:45:48.090046Z","shell.execute_reply":"2023-11-26T17:45:48.089194Z","shell.execute_reply.started":"2023-11-26T17:45:48.081543Z"},"trusted":true},"outputs":[],"source":["def generated_formula(output, vocab):\n","    \"\"\"\n","    output: [shape: (Max_length,vocab_size)]\n","    \"\"\"\n","    output = torch.argmax(output, dim = 1)\n","    output = output.tolist()\n","    formula = ' '.join([vocab.id_to_wd[id] for id in output])\n","    return formula"]},{"cell_type":"code","execution_count":61,"metadata":{"execution":{"iopub.execute_input":"2023-11-26T18:00:31.699279Z","iopub.status.busy":"2023-11-26T18:00:31.698424Z","iopub.status.idle":"2023-11-26T18:00:31.711976Z","shell.execute_reply":"2023-11-26T18:00:31.710943Z","shell.execute_reply.started":"2023-11-26T18:00:31.699250Z"},"trusted":true},"outputs":[],"source":["def train_epoch(dataloader,model, optimizer, criterion, vocab=None):\n","    total_loss = 0\n","    idx = 0\n","    pb = tqdm(dataloader, desc=\"Batch\")\n","    for data in pb:\n","        idx+=1\n","        input_tensor, target_tensor = data['image'].to(device), data['formula'].to(device)\n","        outputs = model(input_tensor, target_tensor)\n","        if(train_dataset and idx%150==0):\n","            generated_formula = [train_dataset.vocab.id_to_wd[token.item()] for token in torch.argmax(outputs, dim=2)[0]]\n","            required_formula = [train_dataset.vocab.id_to_wd[token.item()] for token in target_tensor[0]]\n","            print(f\"Generated: {' '.join(generated_formula)}\")\n","            print(f\"Actual: {' '.join(required_formula)}\")\n","\n","        output_logits = outputs.permute(0,2,1)\n","        \n","        loss = criterion(\n","            output_logits,\n","            target_tensor\n","        )\n","        \n","        #backprop\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step() \n","\n","        total_loss += loss.item()\n","        pb.set_description(f\"Loss: {loss.item()}\")\n","\n","    return total_loss / len(dataloader)\n","\n","def train(train_dataloader, model, n_epochs, optimizer = None, learning_rate=0.001, print_every=1, save_interval=2, save_prefix = 'model'):\n","    start = time.time()\n","    plot_losses = []\n","    print_loss_total = 0  # Reset every print_every\n","\n","    if not optimizer: optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","    criterion = nn.CrossEntropyLoss(ignore_index=train_dataloader.dataset.vocab.wd_to_id[PAD_TOKEN]).to(device) #as stated in assignment\n","\n","    model.train()\n","    for epoch in range(1, n_epochs + 1):\n","        info(f\"Epoch {epoch}\")\n","        loss = train_epoch(train_dataloader, model, optimizer, criterion)\n","        print_loss_total += loss\n","\n","        if epoch % print_every == 0:\n","            print_loss_avg = print_loss_total / print_every\n","            print_loss_total = 0\n","    \n","        if epoch % save_interval == 0:\n","            saveModel(f'/kaggle/working/{save_prefix}_epoch_{epoch}.pt', model.state_dict(), optimizer.state_dict(), loss)    \n","                \n","        info('%s (%d %d%%) %.4f' % (timeSince(start, epoch / n_epochs), epoch, epoch / n_epochs * 100, print_loss_avg))"]},{"cell_type":"markdown","metadata":{},"source":["## Training"]},{"cell_type":"code","execution_count":62,"metadata":{"execution":{"iopub.execute_input":"2023-11-26T18:00:32.221963Z","iopub.status.busy":"2023-11-26T18:00:32.221588Z","iopub.status.idle":"2023-11-26T18:00:32.227622Z","shell.execute_reply":"2023-11-26T18:00:32.226283Z","shell.execute_reply.started":"2023-11-26T18:00:32.221933Z"},"trusted":true},"outputs":[],"source":["\n","batch_size = 32\n","vocab_size = 1000\n","CONTEXT_SIZE = 512\n","HIDDEN_SIZE = 512\n","EMBED_SIZE = 512\n","MAX_EXAMPLES = 1000\n","# image processing\n","transform = transforms.Compose([\n","    transforms.ToPILImage(),\n","    transforms.Grayscale(num_output_channels=3),\n","    transforms.ToTensor(),\n","    transforms.Resize((224, 224)),\n","])"]},{"cell_type":"markdown","metadata":{},"source":["### Load Dataset and Dataloader"]},{"cell_type":"code","execution_count":63,"metadata":{"execution":{"iopub.execute_input":"2023-11-26T18:00:32.839460Z","iopub.status.busy":"2023-11-26T18:00:32.838561Z","iopub.status.idle":"2023-11-26T18:01:05.578622Z","shell.execute_reply":"2023-11-26T18:01:05.577611Z","shell.execute_reply.started":"2023-11-26T18:00:32.839427Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Loading Dataset...\n","Loaded.\n"]}],"source":["#part a\n","hw_train_csv_path = \"data/HandwrittenData/train_hw.csv\"\n","hw_image_root_path = \"data/HandwrittenData/images/train/\"\n","hw_train_dataloader, hw_train_dataset = get_dataloader(hw_train_csv_path, hw_image_root_path, batch_size, transform, max_examples=None, externVocab = train_dataset.vocab)"]},{"cell_type":"markdown","metadata":{},"source":["### Create Model"]},{"cell_type":"code","execution_count":64,"metadata":{"execution":{"iopub.execute_input":"2023-11-26T18:01:05.580499Z","iopub.status.busy":"2023-11-26T18:01:05.580206Z","iopub.status.idle":"2023-11-26T18:01:05.662268Z","shell.execute_reply":"2023-11-26T18:01:05.661501Z","shell.execute_reply.started":"2023-11-26T18:01:05.580473Z"},"trusted":true},"outputs":[],"source":["#create a network instance\n","# model = HandwritingToLatexModel(CONTEXT_SIZE, train_dataset.vocab, n_layers=1, hidden_size= HIDDEN_SIZE, embed_size=EMBED_SIZE, max_seq_len=train_dataset.maxlen).to(device)"]},{"cell_type":"markdown","metadata":{},"source":["### Train"]},{"cell_type":"code","execution_count":65,"metadata":{"execution":{"iopub.status.busy":"2023-11-26T17:52:35.551000Z","iopub.status.idle":"2023-11-26T17:52:35.551378Z","shell.execute_reply":"2023-11-26T17:52:35.551224Z","shell.execute_reply.started":"2023-11-26T17:52:35.551207Z"},"trusted":true},"outputs":[],"source":["def load_from_checkpoint(checkpoint_path, max_len):\n","    model_dicts = torch.load(checkpoint_path, map_location=device)\n","    \n","    model = HandwritingToLatexModel(CONTEXT_SIZE, train_dataset.vocab, n_layers=1, hidden_size= HIDDEN_SIZE, embed_size=EMBED_SIZE, max_seq_len=max_len).to(device)\n","    model.load_state_dict(model_dicts['model_state_dict'])\n","    \n","    optims = torch.optim.Adam(model.parameters(), lr=0.001)\n","    optims.load_state_dict(model_dicts['optimizer_state_dict'])\n","\n","    return model, optims\n","\n","# model, optim = load_from_checkpoint(\"checkpoints/model2.0+12_epoch_6.pt\")\n","\n","#resume training from checkpoints\n","# losses = train(train_dataloader, model, 20, optimizer = optim, save_interval=2, save_prefix = 'model2.0+18')\n"]},{"cell_type":"code","execution_count":66,"metadata":{},"outputs":[],"source":["model_load, optims_load = load_from_checkpoint(\"checkpoints/model3.0_epoch_24.pt\", hw_train_dataset.maxlen)"]},{"cell_type":"markdown","metadata":{},"source":["## Fine Tuning"]},{"cell_type":"code","execution_count":67,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1\n"]},{"name":"stderr","output_type":"stream","text":["Loss: 0.788834273815155:   8%|â–Š         | 22/282 [00:25<05:02,  1.16s/it] \n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[1;32m/Users/samarth/Library/CloudStorage/OneDrive-IITDelhi/Sem5/COL774/assgns/assgn4/Handwriting-to-Latex-ML/main_finetune.ipynb Cell 27\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/samarth/Library/CloudStorage/OneDrive-IITDelhi/Sem5/COL774/assgns/assgn4/Handwriting-to-Latex-ML/main_finetune.ipynb#X44sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m train(hw_train_dataloader, model_load, \u001b[39m20\u001b[39;49m, optimizer \u001b[39m=\u001b[39;49m optims_load, save_interval\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m, save_prefix \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mfineTuned\u001b[39;49m\u001b[39m'\u001b[39;49m)\n","\u001b[1;32m/Users/samarth/Library/CloudStorage/OneDrive-IITDelhi/Sem5/COL774/assgns/assgn4/Handwriting-to-Latex-ML/main_finetune.ipynb Cell 27\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/samarth/Library/CloudStorage/OneDrive-IITDelhi/Sem5/COL774/assgns/assgn4/Handwriting-to-Latex-ML/main_finetune.ipynb#X44sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, n_epochs \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/samarth/Library/CloudStorage/OneDrive-IITDelhi/Sem5/COL774/assgns/assgn4/Handwriting-to-Latex-ML/main_finetune.ipynb#X44sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m     info(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/samarth/Library/CloudStorage/OneDrive-IITDelhi/Sem5/COL774/assgns/assgn4/Handwriting-to-Latex-ML/main_finetune.ipynb#X44sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m     loss \u001b[39m=\u001b[39m train_epoch(train_dataloader, model, optimizer, criterion)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/samarth/Library/CloudStorage/OneDrive-IITDelhi/Sem5/COL774/assgns/assgn4/Handwriting-to-Latex-ML/main_finetune.ipynb#X44sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m     print_loss_total \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/samarth/Library/CloudStorage/OneDrive-IITDelhi/Sem5/COL774/assgns/assgn4/Handwriting-to-Latex-ML/main_finetune.ipynb#X44sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m     \u001b[39mif\u001b[39;00m epoch \u001b[39m%\u001b[39m print_every \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n","\u001b[1;32m/Users/samarth/Library/CloudStorage/OneDrive-IITDelhi/Sem5/COL774/assgns/assgn4/Handwriting-to-Latex-ML/main_finetune.ipynb Cell 27\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/samarth/Library/CloudStorage/OneDrive-IITDelhi/Sem5/COL774/assgns/assgn4/Handwriting-to-Latex-ML/main_finetune.ipynb#X44sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m idx\u001b[39m+\u001b[39m\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/samarth/Library/CloudStorage/OneDrive-IITDelhi/Sem5/COL774/assgns/assgn4/Handwriting-to-Latex-ML/main_finetune.ipynb#X44sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m input_tensor, target_tensor \u001b[39m=\u001b[39m data[\u001b[39m'\u001b[39m\u001b[39mimage\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mto(device), data[\u001b[39m'\u001b[39m\u001b[39mformula\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/samarth/Library/CloudStorage/OneDrive-IITDelhi/Sem5/COL774/assgns/assgn4/Handwriting-to-Latex-ML/main_finetune.ipynb#X44sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m outputs \u001b[39m=\u001b[39m model(input_tensor, target_tensor)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/samarth/Library/CloudStorage/OneDrive-IITDelhi/Sem5/COL774/assgns/assgn4/Handwriting-to-Latex-ML/main_finetune.ipynb#X44sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mif\u001b[39;00m(train_dataset \u001b[39mand\u001b[39;00m idx\u001b[39m%\u001b[39m\u001b[39m150\u001b[39m\u001b[39m==\u001b[39m\u001b[39m0\u001b[39m):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/samarth/Library/CloudStorage/OneDrive-IITDelhi/Sem5/COL774/assgns/assgn4/Handwriting-to-Latex-ML/main_finetune.ipynb#X44sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     generated_formula \u001b[39m=\u001b[39m [train_dataset\u001b[39m.\u001b[39mvocab\u001b[39m.\u001b[39mid_to_wd[token\u001b[39m.\u001b[39mitem()] \u001b[39mfor\u001b[39;00m token \u001b[39min\u001b[39;00m torch\u001b[39m.\u001b[39margmax(outputs, dim\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)[\u001b[39m0\u001b[39m]]\n","File \u001b[0;32m~/.pyenv/versions/3.10.4/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[0;32m~/.pyenv/versions/3.10.4/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n","\u001b[1;32m/Users/samarth/Library/CloudStorage/OneDrive-IITDelhi/Sem5/COL774/assgns/assgn4/Handwriting-to-Latex-ML/main_finetune.ipynb Cell 27\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/samarth/Library/CloudStorage/OneDrive-IITDelhi/Sem5/COL774/assgns/assgn4/Handwriting-to-Latex-ML/main_finetune.ipynb#X44sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, image, target_tensor \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/samarth/Library/CloudStorage/OneDrive-IITDelhi/Sem5/COL774/assgns/assgn4/Handwriting-to-Latex-ML/main_finetune.ipynb#X44sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     context \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder(image)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/samarth/Library/CloudStorage/OneDrive-IITDelhi/Sem5/COL774/assgns/assgn4/Handwriting-to-Latex-ML/main_finetune.ipynb#X44sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     outputs, hidden, cell \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecoder(context, target_tensor)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/samarth/Library/CloudStorage/OneDrive-IITDelhi/Sem5/COL774/assgns/assgn4/Handwriting-to-Latex-ML/main_finetune.ipynb#X44sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m outputs\n","File \u001b[0;32m~/.pyenv/versions/3.10.4/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[0;32m~/.pyenv/versions/3.10.4/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n","\u001b[1;32m/Users/samarth/Library/CloudStorage/OneDrive-IITDelhi/Sem5/COL774/assgns/assgn4/Handwriting-to-Latex-ML/main_finetune.ipynb Cell 27\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/samarth/Library/CloudStorage/OneDrive-IITDelhi/Sem5/COL774/assgns/assgn4/Handwriting-to-Latex-ML/main_finetune.ipynb#X44sZmlsZQ%3D%3D?line=98'>99</a>\u001b[0m         embedding \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed(torch\u001b[39m.\u001b[39margmax(output, dim \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m))\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/samarth/Library/CloudStorage/OneDrive-IITDelhi/Sem5/COL774/assgns/assgn4/Handwriting-to-Latex-ML/main_finetune.ipynb#X44sZmlsZQ%3D%3D?line=100'>101</a>\u001b[0m lstm_input \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([context, embedding], dim \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/samarth/Library/CloudStorage/OneDrive-IITDelhi/Sem5/COL774/assgns/assgn4/Handwriting-to-Latex-ML/main_finetune.ipynb#X44sZmlsZQ%3D%3D?line=102'>103</a>\u001b[0m hidden, cell \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlstm(lstm_input, (hidden, cell))\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/samarth/Library/CloudStorage/OneDrive-IITDelhi/Sem5/COL774/assgns/assgn4/Handwriting-to-Latex-ML/main_finetune.ipynb#X44sZmlsZQ%3D%3D?line=103'>104</a>\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlinear(hidden)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/samarth/Library/CloudStorage/OneDrive-IITDelhi/Sem5/COL774/assgns/assgn4/Handwriting-to-Latex-ML/main_finetune.ipynb#X44sZmlsZQ%3D%3D?line=104'>105</a>\u001b[0m outputs\u001b[39m.\u001b[39mappend(output)\n","File \u001b[0;32m~/.pyenv/versions/3.10.4/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[0;32m~/.pyenv/versions/3.10.4/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n","File \u001b[0;32m~/.pyenv/versions/3.10.4/lib/python3.10/site-packages/torch/nn/modules/rnn.py:1347\u001b[0m, in \u001b[0;36mLSTMCell.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m   1344\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1345\u001b[0m     hx \u001b[39m=\u001b[39m (hx[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m), hx[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)) \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_batched \u001b[39melse\u001b[39;00m hx\n\u001b[0;32m-> 1347\u001b[0m ret \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39;49mlstm_cell(\n\u001b[1;32m   1348\u001b[0m     \u001b[39minput\u001b[39;49m, hx,\n\u001b[1;32m   1349\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight_ih, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight_hh,\n\u001b[1;32m   1350\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias_ih, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias_hh,\n\u001b[1;32m   1351\u001b[0m )\n\u001b[1;32m   1353\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_batched:\n\u001b[1;32m   1354\u001b[0m     ret \u001b[39m=\u001b[39m (ret[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39msqueeze(\u001b[39m0\u001b[39m), ret[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39msqueeze(\u001b[39m0\u001b[39m))\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["train(hw_train_dataloader, model_load, 30, optimizer = optims_load, save_interval=4, save_prefix = 'fineTuned')"]},{"cell_type":"markdown","metadata":{},"source":["## BLEU"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import math\n","from nltk import word_tokenize\n","from collections import Counter\n","from nltk.util import ngrams\n","\n","\n","class BLEU(object):\n","    @staticmethod\n","    def compute(candidate, references, weights):\n","        candidate = [c.lower() for c in candidate]\n","        references = [[r.lower() for r in reference] for reference in references]\n","\n","        p_ns = (BLEU.modified_precision(candidate, references, i) for i, _ in enumerate(weights, start=1))\n","        s = math.fsum(w * math.log(p_n) for w, p_n in zip(weights, p_ns) if p_n)\n","\n","        bp = BLEU.brevity_penalty(candidate, references)\n","        return bp * math.exp(s)\n","\n","    @staticmethod\n","    def modified_precision(candidate, references, n):\n","        counts = Counter(ngrams(candidate, n))\n","\n","        if not counts:\n","            return 0\n","\n","        max_counts = {}\n","        for reference in references:\n","            reference_counts = Counter(ngrams(reference, n))\n","            for ngram in counts:\n","                max_counts[ngram] = max(max_counts.get(ngram, 0), reference_counts[ngram])\n","\n","        clipped_counts = dict((ngram, min(count, max_counts[ngram])) for ngram, count in counts.items())\n","\n","        return sum(clipped_counts.values()) / sum(counts.values())\n","    \n","    @staticmethod\n","    def brevity_penalty(candidate, references):\n","        c = len(candidate)\n","        # r = min(abs(len(r) - c) for r in references)\n","        r = min(len(r) for r in references)\n","\n","        if c > r:\n","            return 1\n","        else:\n","            return math.exp(1 - r / c)\n","      "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Loading Dataset...\n","Loaded.\n"]}],"source":["test_csv_path = \"data/SyntheticData/test.csv\"\n","image_root_path = \"data/SyntheticData/images/\"\n","test_dataloader, test_dataset = get_dataloader(test_csv_path, image_root_path, 32, transform, max_examples=None, shuffle=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model_loaded, _ = load_from_checkpoint(\"checkpoints/model3.0+6_epoch_12.pt\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|          | 0/279 [00:04<?, ?it/s]\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[1;32m/Users/samarth/Library/CloudStorage/OneDrive-IITDelhi/Sem5/COL774/assgns/assgn4/Handwriting-to-Latex-ML/main_gigachad.ipynb Cell 29\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/samarth/Library/CloudStorage/OneDrive-IITDelhi/Sem5/COL774/assgns/assgn4/Handwriting-to-Latex-ML/main_gigachad.ipynb#X36sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m outputs_final \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39margmax(outputs, dim\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/samarth/Library/CloudStorage/OneDrive-IITDelhi/Sem5/COL774/assgns/assgn4/Handwriting-to-Latex-ML/main_gigachad.ipynb#X36sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(outputs)):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/samarth/Library/CloudStorage/OneDrive-IITDelhi/Sem5/COL774/assgns/assgn4/Handwriting-to-Latex-ML/main_gigachad.ipynb#X36sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     \u001b[39m# generated_formula = [train_dataset.vocab.id_to_wd[token.item()] for token in outputs_final[j]]\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/samarth/Library/CloudStorage/OneDrive-IITDelhi/Sem5/COL774/assgns/assgn4/Handwriting-to-Latex-ML/main_gigachad.ipynb#X36sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     generated_formula \u001b[39m=\u001b[39m train_dataset\u001b[39m.\u001b[39;49mvocab\u001b[39m.\u001b[39;49mdecode(outputs_final[j])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/samarth/Library/CloudStorage/OneDrive-IITDelhi/Sem5/COL774/assgns/assgn4/Handwriting-to-Latex-ML/main_gigachad.ipynb#X36sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     \u001b[39m# required_formula = [test_dataloader.dataset.vocab.id_to_wd[token.item()] for token in target_tensor[j]]\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/samarth/Library/CloudStorage/OneDrive-IITDelhi/Sem5/COL774/assgns/assgn4/Handwriting-to-Latex-ML/main_gigachad.ipynb#X36sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     required_formula \u001b[39m=\u001b[39m test_dataloader\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39mvocab\u001b[39m.\u001b[39mdecode(target_tensor[j])\n","\u001b[1;32m/Users/samarth/Library/CloudStorage/OneDrive-IITDelhi/Sem5/COL774/assgns/assgn4/Handwriting-to-Latex-ML/main_gigachad.ipynb Cell 29\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/samarth/Library/CloudStorage/OneDrive-IITDelhi/Sem5/COL774/assgns/assgn4/Handwriting-to-Latex-ML/main_gigachad.ipynb#X36sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/samarth/Library/CloudStorage/OneDrive-IITDelhi/Sem5/COL774/assgns/assgn4/Handwriting-to-Latex-ML/main_gigachad.ipynb#X36sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mInput shape: (seq_len,)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/samarth/Library/CloudStorage/OneDrive-IITDelhi/Sem5/COL774/assgns/assgn4/Handwriting-to-Latex-ML/main_gigachad.ipynb#X36sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39mOutput Shape: seq_len -> python list\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/samarth/Library/CloudStorage/OneDrive-IITDelhi/Sem5/COL774/assgns/assgn4/Handwriting-to-Latex-ML/main_gigachad.ipynb#X36sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/samarth/Library/CloudStorage/OneDrive-IITDelhi/Sem5/COL774/assgns/assgn4/Handwriting-to-Latex-ML/main_gigachad.ipynb#X36sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39m# decoded = []\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/samarth/Library/CloudStorage/OneDrive-IITDelhi/Sem5/COL774/assgns/assgn4/Handwriting-to-Latex-ML/main_gigachad.ipynb#X36sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39m# for id in formula:\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/samarth/Library/CloudStorage/OneDrive-IITDelhi/Sem5/COL774/assgns/assgn4/Handwriting-to-Latex-ML/main_gigachad.ipynb#X36sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39m#     idx = id.item()\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/samarth/Library/CloudStorage/OneDrive-IITDelhi/Sem5/COL774/assgns/assgn4/Handwriting-to-Latex-ML/main_gigachad.ipynb#X36sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39m#     else:\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/samarth/Library/CloudStorage/OneDrive-IITDelhi/Sem5/COL774/assgns/assgn4/Handwriting-to-Latex-ML/main_gigachad.ipynb#X36sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39m#         decoded.append(UNK_TOKEN)\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/samarth/Library/CloudStorage/OneDrive-IITDelhi/Sem5/COL774/assgns/assgn4/Handwriting-to-Latex-ML/main_gigachad.ipynb#X36sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin([\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mid_to_wd[idx\u001b[39m.\u001b[39mitem()] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m formula])\n","\u001b[1;32m/Users/samarth/Library/CloudStorage/OneDrive-IITDelhi/Sem5/COL774/assgns/assgn4/Handwriting-to-Latex-ML/main_gigachad.ipynb Cell 29\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/samarth/Library/CloudStorage/OneDrive-IITDelhi/Sem5/COL774/assgns/assgn4/Handwriting-to-Latex-ML/main_gigachad.ipynb#X36sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/samarth/Library/CloudStorage/OneDrive-IITDelhi/Sem5/COL774/assgns/assgn4/Handwriting-to-Latex-ML/main_gigachad.ipynb#X36sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mInput shape: (seq_len,)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/samarth/Library/CloudStorage/OneDrive-IITDelhi/Sem5/COL774/assgns/assgn4/Handwriting-to-Latex-ML/main_gigachad.ipynb#X36sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39mOutput Shape: seq_len -> python list\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/samarth/Library/CloudStorage/OneDrive-IITDelhi/Sem5/COL774/assgns/assgn4/Handwriting-to-Latex-ML/main_gigachad.ipynb#X36sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/samarth/Library/CloudStorage/OneDrive-IITDelhi/Sem5/COL774/assgns/assgn4/Handwriting-to-Latex-ML/main_gigachad.ipynb#X36sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39m# decoded = []\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/samarth/Library/CloudStorage/OneDrive-IITDelhi/Sem5/COL774/assgns/assgn4/Handwriting-to-Latex-ML/main_gigachad.ipynb#X36sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39m# for id in formula:\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/samarth/Library/CloudStorage/OneDrive-IITDelhi/Sem5/COL774/assgns/assgn4/Handwriting-to-Latex-ML/main_gigachad.ipynb#X36sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39m#     idx = id.item()\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/samarth/Library/CloudStorage/OneDrive-IITDelhi/Sem5/COL774/assgns/assgn4/Handwriting-to-Latex-ML/main_gigachad.ipynb#X36sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39m#     else:\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/samarth/Library/CloudStorage/OneDrive-IITDelhi/Sem5/COL774/assgns/assgn4/Handwriting-to-Latex-ML/main_gigachad.ipynb#X36sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39m#         decoded.append(UNK_TOKEN)\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/samarth/Library/CloudStorage/OneDrive-IITDelhi/Sem5/COL774/assgns/assgn4/Handwriting-to-Latex-ML/main_gigachad.ipynb#X36sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin([\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mid_to_wd[idx\u001b[39m.\u001b[39;49mitem()] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m formula])\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["#testing the model\n","import time\n","\n","model_loaded.eval()\n","predictions = []\n","gts = []\n","pb = tqdm(test_dataloader, total=len(test_dataloader))\n","with torch.no_grad():\n","    for batch in pb:\n","        input_tensor = batch['image'].to(device)\n","        target_tensor = batch['formula'].to(device)\n","        outputs = model_loaded(input_tensor)\n","        outputs_final = torch.argmax(outputs, dim=2)\n","        for j in range(len(outputs)):\n","            # generated_formula = [train_dataset.vocab.id_to_wd[token.item()] for token in outputs_final[j]]\n","            generated_formula = train_dataset.vocab.decode(outputs_final[j])\n","            # required_formula = [test_dataloader.dataset.vocab.id_to_wd[token.item()] for token in target_tensor[j]]\n","            required_formula = test_dataloader.dataset.vocab.decode(target_tensor[j])\n","            predictions.append(generated_formula)\n","            gts.append(required_formula)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["N = len(predictions)\n","totalBleu = 0\n","for i in len(predictions):\n","    gen_formula = predictions[i]\n","    req_formula = gts[i]\n","    gen_trim = []\n","    for tken in gen_formula:\n","        if tken == END_TOKEN:\n","            break\n","        gen_trim.append(tken)\n","    req_trim = []\n","    for tken in req_formula:\n","        if tken == END_TOKEN:\n","            break\n","        req_trim.append(tken)\n","    gen_formula = gen_trim[1:]\n","    req_formula = req_trim[1:]\n","    bleu = BLEU.compute(gen_formula, req_formula, [1/4, 1/4, 1/4, 1/4])\n","    totalBleu += bleu\n","\n","print(f\"Macro Bleu Score: {totalBleu/N}\")"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"databundleVersionId":6947127,"sourceId":63599,"sourceType":"competition"}],"dockerImageVersionId":30588,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"}},"nbformat":4,"nbformat_minor":4}
